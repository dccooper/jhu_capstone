dataset:con <- file("en_US.twitter.txt", "r") readLines(con, 1)
setwd("~/projects/jhu_capstone")
dataset:con <- file("/data/final/en_US/en_US.twitter.txt", "r") readLines(con, 1)
dataset:con <- file("/data/final/en_US/en_US.twitter.txt", "r")
dataset:con <- file("data/final/en_US/en_US.twitter.txt", "r")
?datasets
dataset:con
en_tw <- file("/data/final/en_US/en_US.twitter.txt", "r")
en_tw <- file("data/final/en_US/en_US.twitter.txt", "r")
en_nw <- file("data/final/en_US/en_US.news.txt", "r")
en_bl <- file("data/final/en_US/en_US.blogs.txt", "r")
en_tw_subset <- readLines(en_tw, 100)
en_nw_subset <- readLines(en_nw, 100)
en_bl_subset <- readLines(en_bl, 100)
de_tw <- file("data/final/de_DE/de_DE.twitter.txt", "r")
de_nw <- file("data/final/de_DE/de_DE.news.txt", "r")
de_bl <- file("data/final/de_DE/de_DE.blogs.txt", "r")
## German Corpus subset files
de_tw_subset <- readLines(de_tw, 100)
de_nw_subset <- readLines(de_nw, 100)
de_bl_subset <- readLines(de_bl, 100)
fi_tw <- file("data/final/fi_FI/fi_FI.twitter.txt", "r")
fi_nw <- file("data/final/fi_FI/fi_FI.news.txt", "r")
fi_bl <- file("data/final/fi_FI/fi_FI.blogs.txt", "r")
## Finnish Corpus subset files
fi_tw_subset <- readLines(fi_tw, 100)
fi_nw_subset <- readLines(fi_nw, 100)
fi_bl_subset <- readLines(fi_bl, 100)
ru_tw <- file("data/final/ru_RU/ru_RU.twitter.txt", "r")
ru_nw <- file("data/final/ru_RU/ru_RU.news.txt", "r")
ru_bl <- file("data/final/ru_RU/ru_RU.blogs.txt", "r")
## Russian Corpus subset files
ru_tw_subset <- readLines(ru_tw, 100)
ru_nw_subset <- readLines(ru_nw, 100)
ru_bl_subset <- readLines(ru_bl, 100)
set.seed(1000)
en_tw_subset <- sample(en_tw, 500)
en_nw_subset <- sample(en_nw, 500)
en_bl_subset <- sample(en_bl, 500)
?sample
en_tw_subset <- sample(en_tw, 500)
en_tw <- file("data/final/en_US/en_US.twitter.txt", "r")
en_tw_subset <- sample(en_tw, 500)
list.files("data/final")
en_tw_subset <- readLines(en_tw)
en_nw <- file("data/final/en_US/en_US.news.txt", "r")
en_bl <- file("data/final/en_US/en_US.blogs.txt", "r")
en_tw_subset <- readLines(en_tw, encoding="UTF-8")
en_tw_subset <- readLines(en_tw, encoding = "UTF-8")
en_nw <- file("data/final/en_US/en_US.news.txt", "r", open = "rb")
en_nw <- file("data/final/en_US/en_US.news.txt", open = "rb")
en_nw_subset <- readLines(en_nw, encoding = "UTF-8")
file.info("data/final/en_US/en_US.blogs.txt")$size
en_tw_subset <- readLines(en_tw)
en_bl_subset <- readLines(en_bl)
en_tw <- file("data/final/en_US/en_US.twitter.txt", "r")
en_tw_subset <- readLines(en_tw)
max(nchar(en_tw_subset))
max(nchar(en_nw_subset))
max(nchar(en_bl_subset))
love_count <- sum(grepl("love", en_bl_subset))
hate_count <- sum(grepl("hate", en_tw_subset))
love_count / hate_count
biostats <- grep("biostats", en_tw_subset)
twitter[biostats]
en_tw_subset[biostats]
sum(grepl("A computer once beat me at chess, but it was no match for me at kickboxing", en_tw_subset))
rm("hate_count")
rm("love_count")
rm("biostats")
rm("en_tw,
en_nw,
en_bl")
rm("en_tw,en_nw,en_bl")
rm("en_tw","en_nw","en_bl")
?lazyload
??lazyLoad
?save
save(list = c("en_tw_raw", "en_nw_raw", "en_bl_raw"), file="english.RData")
en_tw <- file("data/final/en_US/en_US.twitter.txt", "r")
en_nw <- file("data/final/en_US/en_US.news.txt", open = "rb")
en_bl <- file("data/final/en_US/en_US.blogs.txt", "r")
## English Corpus subset files
en_tw_raw <- readLines(en_tw)
en_nw_raw <- readLines(en_nw, encoding = "UTF-8")
en_bl_raw <- readLines(en_bl)
en_tw_raw <- readLines(en_tw, encoding = "UTF-8")
en_tw_raw <- readLines(en_tw)
en_tw <- file("data/final/en_US/en_US.twitter.txt", "r")
en_tw_raw <- readLines(en_tw)
save(list = c("en_tw_raw", "en_nw_raw", "en_bl_raw"), file="data/english.RData")
load("~/projects/jhu_capstone/data/english.RData")
e = local({load("data/english.RData"); environment()})
tools:::makeLazyLoadDB(e, "english")
tools:::makeLazyLoadDB(e, "data/english")
close("en_tw","en_nw","en_bl")
lazyLoad("data/english")
lazyLoad("data/english.rdb")
## German Corpus raw files
de_tw <- file("data/final/de_DE/de_DE.twitter.txt", "r")
de_nw <- file("data/final/de_DE/de_DE.news.txt", open = "rb")
de_bl <- file("data/final/de_DE/de_DE.blogs.txt", "r")
## German Corpus subset files
de_tw_raw <- readLines(de_tw)
de_nw_raw <- readLines(de_nw, encoding = "UTF-8")
de_bl_raw <- readLines(de_bl)
#Combine Datasets into a Rdatafile
save(list = c("de_tw_raw", "de_nw_raw", "de_bl_raw"), file="data/english.RData")
#Close the connections and remove the unused data
close("de_tw","de_nw","de_bl")
rm("de_tw","de_nw","de_bl")
``
set.seed(1000)
# Importing the data
## English Corpus raw files
en_tw <- file("data/final/en_US/en_US.twitter.txt", "r")
en_nw <- file("data/final/en_US/en_US.news.txt", open = "rb")
en_bl <- file("data/final/en_US/en_US.blogs.txt", "r")
## English Corpus subset files
en_tw_raw <- readLines(en_tw)
en_nw_raw <- readLines(en_nw, encoding = "UTF-8")
en_bl_raw <- readLines(en_bl)
#Combine Datasets into a Rdatafile
save(list = c("en_tw_raw", "en_nw_raw", "en_bl_raw"), file="data/english.RData")
#Close the connections and remove the unused data
close("en_tw","en_nw","en_bl")
rm("en_tw","en_nw","en_bl")
## German Corpus raw files
de_tw <- file("data/final/de_DE/de_DE.twitter.txt", "r")
de_nw <- file("data/final/de_DE/de_DE.news.txt", open = "rb")
de_bl <- file("data/final/de_DE/de_DE.blogs.txt", "r")
## German Corpus subset files
de_tw_raw <- readLines(de_tw)
de_nw_raw <- readLines(de_nw, encoding = "UTF-8")
de_bl_raw <- readLines(de_bl)
#Combine Datasets into a Rdatafile
save(list = c("de_tw_raw", "de_nw_raw", "de_bl_raw"), file="data/German.RData")
#Close the connections and remove the unused data
close("de_tw","de_nw","de_bl")
rm("de_tw","de_nw","de_bl")
## Finnish Corpus raw files
fi_tw <- file("data/final/fi_FI/fi_FI.twitter.txt", "r")
fi_nw <- file("data/final/fi_FI/fi_FI.news.txt", open = "rb")
fi_bl <- file("data/final/fi_FI/fi_FI.blogs.txt", "r")
## Finnish Corpus subset files
fi_tw_subset <- readLines(fi_tw)
fi_nw_subset <- readLines(fi_nw, encoding = "UTF-8")
fi_bl_subset <- readLines(fi_bl)
#Combine Datasets into a Rdatafile
save(list = c("fi_tw_raw", "fi_nw_raw", "fi_bl_raw"), file="data/finnish.RData")
#Close the connections and remove the unused data
close("fi_tw","fi_nw","fi_bl")
rm("fi_tw","fi_nw","fi_bl")
## Russian Corpus raw files
ru_tw <- file("data/final/ru_RU/ru_RU.twitter.txt", "r")
ru_nw <- file("data/final/ru_RU/ru_RU.news.txt", open = "rb")
ru_bl <- file("data/final/ru_RU/ru_RU.blogs.txt", "r")
## Russian Corpus subset files
ru_tw_subset <- readLines(ru_tw)
ru_nw_subset <- readLines(ru_nw, encoding = "UTF-8")
ru_bl_subset <- readLines(ru_bl)
#Combine Datasets into a Rdatafile
save(list = c("ru_tw_raw", "ru_nw_raw", "ru_bl_raw"), file="data/russian.RData")
#Close the connections and remove the unused data
close("ru_tw","ru_nw","ru_bl")
rm("ru_tw","ru_nw","ru_bl")
## Finnish Corpus raw files
fi_tw <- file("data/final/fi_FI/fi_FI.twitter.txt", "r")
fi_nw <- file("data/final/fi_FI/fi_FI.news.txt", open = "rb")
fi_bl <- file("data/final/fi_FI/fi_FI.blogs.txt", "r")
## Finnish Corpus subset files
fi_tw_raw <- readLines(fi_tw)
fi_nw_raw <- readLines(fi_nw, encoding = "UTF-8")
fi_bl_raw <- readLines(fi_bl)
#Combine Datasets into a Rdatafile
save(list = c("fi_tw_raw", "fi_nw_raw", "fi_bl_raw"), file="data/finnish.RData")
#Close the connections and remove the unused data
close("fi_tw","fi_nw","fi_bl")
rm("fi_tw","fi_nw","fi_bl")
## Russian Corpus raw files
ru_tw <- file("data/final/ru_RU/ru_RU.twitter.txt", "r")
ru_nw <- file("data/final/ru_RU/ru_RU.news.txt", open = "rb")
ru_bl <- file("data/final/ru_RU/ru_RU.blogs.txt", "r")
## Russian Corpus subset files
ru_tw_raw <- readLines(ru_tw)
ru_nw_raw <- readLines(ru_nw, encoding = "UTF-8")
ru_bl_raw <- readLines(ru_bl)
#Combine Datasets into a Rdatafile
save(list = c("ru_tw_raw", "ru_nw_raw", "ru_bl_raw"), file="data/russian.RData")
#Close the connections and remove the unused data
close("ru_tw","ru_nw","ru_bl")
rm("ru_tw","ru_nw","ru_bl")
load("data/english.RData")
load("data/German.RData")
load("data/russian.RData")
load("data/finnish.RData")
en_tw_sample <- sample(en_tw_raw, 1000)
en_bl_sample <- sample(en_bl_raw, 1000)
en_nw_sample <- sample(en_nw_raw, 1000)
de_tw_sample <- sample(de_tw_raw, 1000)
de_bl_sample <- sample(de_bl_raw, 1000)
de_nw_sample <- sample(de_nw_raw, 1000)
fi_tw_sample <- sample(fi_tw_raw, 1000)
fi_bl_sample <- sample(fi_bl_raw, 1000)
fi_nw_sample <- sample(fi_nw_raw, 1000)
ru_tw_sample <- sample(ru_tw_raw, 1000)
ru_bl_sample <- sample(ru_bl_raw, 1000)
ru_nw_sample <- sample(ru_nw_raw, 1000)
rm("en_tw_raw", "en_nw_raw", "en_bl_raw")
m("de_tw_raw", "de_nw_raw", "de_bl_raw")
rm("ru_tw_raw", "ru_nw_raw", "ru_bl_raw")
rm("fi_tw_raw", "fi_nw_raw", "fi_bl_raw")
rm("de_tw_raw", "de_nw_raw", "de_bl_raw")
save(file= "data/sample_data.RData")
?save
save.image(file= "data/sample_data.RData")
